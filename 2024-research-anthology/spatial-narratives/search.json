[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial Narratives Project",
    "section": "",
    "text": "Summer 2024\n      Spatial Narratives Project\n        \n        Understanding imprecise space and time in narratives through qualitative representations, reasoning, and visualization is an international collaboration with the aim to produce new tools, datasets, and knowledge about the way humans understand and represent their place in space and time through narratives. Because narratives are complex, it is necessary to develop new tools and ontologies for identifying the rich spatial and temporal settings for what we call sense of place. The project seeks to go beyond conventional methods for extracting place names and geonouns in order to understand these features relationally and, where possible, comparatively in the context of large text corpora—specifically, a corpus of Lake District travel writing and a corpus of Holocaust testimonies. Finally, the project works with external partners in the museum and cultural heritage spheres in order to bring these tools and concepts to a broader public.\n      \n      \n    \n    \n    \n        \n        \n          Project Members\n        \n        \n          \n            Project Member\n          \n          \n            Designation\n          \n          \n            ORCID\n          \n        \n            \n          \n            Zephyr Frank\n          \n          \n            Professor of History, and Environmental Social Sciences\n          \n          \n        \n            \n          \n            Max Vandervelden\n          \n          \n            Intern - Summer, 2024\n          \n          \n        \n          \n        \n      \n\n      \n  \n  Developing Spatial Narratives With Large-Language Models\n  \n  Max Vandervelden\n  \n  My project this summer focused on analyzing spatial narratives from accounts of the Lake District. The Lake District corpus comprises works dating from the mid 1800s-1900s. These works consist of traveler’s journals describing journeys throughout the Lake District in England. This corpus, comprising approximately 54,000 sentences, offers an invaluable window into the experiences and observations of visitors during this period.\n  \n  \n  \n  Figure 1. Locating where Lake District is located in the UK.\n  \n  \n  My primary work on this project consisted of (1) comparing methods of emotion sentiment tagging of this text and (2) analyzing relationships between authors in the corpus based on their overarching narrative style. Emotion classification and sentiment tagging can be one of the most useful ways in which to describe a narrative and its progress over time. One initial challenge I faced when analyzing this corpus was what factors make a “distinct” emotion. When defining emotions, most researchers use and continue to rely on Paul Eckman’s classic 6 emotions — anger, surprise, disgust, enjoyment, fear, and sadness. Research from Alan Cowen, however, in analyzing distinct facial changes indicates that up to 28 distinct emotions may exist. Ultimately, I tried multiple approaches. I compared the effectiveness of emotion sentiment tagging between a lighter distilled and fine-tuned model and a larger, more general zero-shot approach. The first model tested was a fine-tuned distilled model developed from the XtremeDistilTransformers framework (Mukherjee et al. 2021). A distilled model is one which usually has a smaller overall size, but trains on the outputs of a larger weight “teacher” model. This process enables it to be more efficient and classify passages faster. The resulting model then “learned” (fine-tuned) on Google GoEmotions dataset, a corpus of 58k text passages, each human-evaluated for multi-label emotion classes. One notable characteristic of the GoEmotions dataset was, unlike using Ekman’s emotions, it separates all training passages into Cowen’s more detailed 28-emotion classifications. In comparison, my zero-shot approach involved using a more general intelligence model – ChatGPT 3.5-turbo. Models like these are “zero-shot” in that they are not trained or “learn” on underlying data. Instead, its responses rely on a vast amount of underlying more general text. Overall, when randomly sampling the text (n = 100), we found slightly better results in human ground-truth assessment for the distilled model in comparison to the zero-shot LLM approach, but both left something to be desired. Once emotion classification was completed, I worked to develop a more uniting comparison between different authors in the corpus and their writing styles. Factors considered in a writer’s unique “narrative” consisted of details like punctuation frequency, the emotional sentiment of their passages, and their usage of different geographic nouns and place names.\n  \n  \n  \n  Figure 2. Graph of different emergent narratives by time period.\n  \n  \n  \n  \n  \n  Figure 3. Graph of large differences in emotional “charge” with different writing styles."
  }
]